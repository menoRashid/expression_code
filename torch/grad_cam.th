require 'image'
npy4th = require 'npy4th'
require 'data_face';
require 'cunn'
require 'cudnn'
require 'nn';
require 'optim'
require 'torchx';
require 'gnuplot';
dump=require 'dump';
visualize=require 'visualize';
utils = require 'misc.utils'


function unMean(training_data,mean,std)
	local mean=mean:view(1,mean:size(1),mean:size(2),mean:size(3));
	local std=std:view(1,std:size(1),std:size(2),std:size(3));
	mean=torch.repeatTensor(mean,training_data:size(1),1,1,1):type(training_data:type());
	std=torch.repeatTensor(std,training_data:size(1),1,1,1):type(training_data:type());
	training_data=torch.cmul(training_data,std)+mean;
	return training_data;
end	

function main(params) 
    print ('setting_threads');
    torch.setnumthreads(1);
	local out_dir=params.outDir
    local net_file=params.model
    if params.limit<0 then
    	params.limit=nil;
    end
    
    paths.mkdir(out_dir);
    local out_dir_intermediate=paths.concat(out_dir,'images');
    paths.mkdir(out_dir_intermediate);
    local out_file_log=paths.concat(out_dir_intermediate,'log.txt');
    local out_file_pred_labels_post='_pred_labels.npy';

    local logger=torch.DiskFile(out_file_log,'w');

    logger:writeString(dump.tostring(params)..'\n');
    print (params);

    cutorch.setDevice(params.gpu);


    logger:writeString(dump.tostring('loading network')..'\n');
    print ('loading network');
    local net = torch.load(net_file);
    -- net:remove(#net);
    -- net:remove(12);
    logger:writeString(dump.tostring('done loading network')..'\n');
    print ('done loading network');
    print (net);

    logger:writeString(dump.tostring('making cuda')..'\n');
    print ('making cuda');
    net = net:cuda();
    logger:writeString(dump.tostring('done')..'\n');
    print ('done');

    logger:writeString(dump.tostring('loading params')..'\n');
    print ('loading params');
    local parameters, gradParameters = net:parameters()
    logger:writeString(dump.tostring('loading done')..'\n');
    print ('loading done');
    data_params={file_path=params.val_data_path,
                batch_size=params.batchSizeTest,
                mean_file=params.mean_im_path,
                std_file=params.std_im_path,
                augmentation=false,
                limit=params.limit};
	vd=data_face(data_params);

	local val_losses={};
	local val_losses_iter={};

	local net_gb= net:clone();
	net_gb:replace(utils.guidedbackprop);
	net_gb:evaluate();
	net_gb=net_gb:cuda();
	net:training();
	print ('training',net.train);
	net:evaluate();
	print ('evaluating',net.train);
    
    -- local i=1;

	local emotions={'neutral', 'anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise'} 
	local layer_to_viz=params.layer_to_viz;

    for i=1,params.iterationsTest do
    	net:zeroGradParameters();
    	net_gb:zeroGradParameters();
	    local out_file_pred_labels=paths.concat(out_dir,i..out_file_pred_labels_post);
		-- for emotion_to_viz=1,#emotions do
		vd:getTrainingData();

	    vd.training_set.data=vd.training_set.data:cuda();
		vd.training_set.label=vd.training_set.label:cuda();
		local batch_inputs=vd.training_set.data;
		local batch_targets=vd.training_set.label;
		local outputs=net:forward(batch_inputs);
		local outputs_gb= net_gb:forward(batch_inputs);

		local scores, pred_labels = torch.max(outputs, 2);
		pred_labels = pred_labels:type(batch_targets:type());
	    pred_labels = pred_labels:view(batch_targets:size());

	    local doutput_pred = utils.create_grad_input_batch(net.modules[#net.modules], pred_labels)
	    local gcam_pred = utils.grad_cam_batch(net, layer_to_viz, doutput_pred);
	    net:zeroGradParameters();
	    local doutput_gt =	utils.create_grad_input_batch(net.modules[#net.modules], batch_targets)
	    local gcam_gt = utils.grad_cam_batch(net, layer_to_viz, doutput_gt);
	    print (doutput_pred:size());
	    local gb_viz_pred = net_gb:backward(batch_inputs, doutput_pred)
	    net_gb:zeroGradParameters();
	    local gb_viz_gt = net_gb:backward(batch_inputs, doutput_gt)
	    
	    local inputs_org=unMean(batch_inputs,vd.mean_im,vd.std_im):div(255):float();
	    local conv_size=5;
	    for gt_pred=1,2 do
	    	local gcam_curr;
	    	local gb_viz_curr;
	    	local out_file_pre=paths.concat(out_dir_intermediate,i..'_');
	    	local out_file_post;
	    	if gt_pred==1 then
	    		gcam_curr=gcam_pred;
	    		gb_viz_curr=gb_viz_pred;
	    		out_file_post='_pred.jpg';
	    	else
	    		gcam_curr=gcam_gt;
	    		gb_viz_curr=gb_viz_gt;
	    		out_file_post='_gt.jpg';
	    	end

		    for im_num=1,inputs_org:size(1) do
		    	local gcam=gcam_curr[im_num]:clone()
		    	if not torch.all(torch.eq(gcam_pred[im_num],gcam_gt[im_num])) then
		    		print (im_num);
		    	end
		    	
		    	local gcam=image.scale(gcam:float(), inputs_org:size(3), inputs_org:size(4));
		    	local gb_viz=gb_viz_curr[im_num][1]:float();
		    	local gb_gcam=torch.cmul(gcam,gb_viz);
		    	local gb_gcam_org  = gb_gcam:clone();
		    	local hm = utils.to_heatmap(gcam)

		    	gb_gcam=torch.sum(gb_gcam,1);
				gb_gcam=torch.abs(gb_gcam);
				gb_gcam=gb_gcam-torch.min(gb_gcam);
				gb_gcam:div(torch.max(gb_gcam));

				local out_file_org=out_file_pre..im_num..'_org.jpg';
				local out_file_hm=out_file_pre..im_num..'_hm'..out_file_post;
				local out_file_gb_gcam=out_file_pre..im_num..'_gb_gcam'..out_file_post;
				local out_file_gb_gcam_org=out_file_pre..im_num..'_gb_gcam_org'..out_file_post;
				local out_file_gb_gcam_th=out_file_pre..im_num..'_gb_gcam_th'..out_file_post;
				local im_org = inputs_org[im_num][1]:clone();
				-- local im_g = image.convolve(im_org,torch.ones(10,10):float(),'same');
				-- print (image.gaussian(2*conv_size+1,2*conv_size+1):float())
				local im_g = image.convolve(im_org,image.gaussian(2*conv_size+1,2*conv_size+1):float(),'same');

				local out_file_g = out_file_pre..im_num..'_gaussian'..out_file_post;
				image.save(out_file_g,image.toDisplayTensor(im_g));
				
				im_g:div(torch.max(im_g));

				local gb_gcam_vals=torch.sort(gb_gcam:view(-1),1,true);
				local idx=math.floor(gb_gcam_vals:size(1)*0.05);
				local gb_gcam_th =torch.zeros(gb_gcam:size()):type(gb_gcam:type());
				gb_gcam_th[gb_gcam:ge(gb_gcam_vals[idx])]=1;
				-- gb_gcam_th = image.convolve(gb_gcam_th,torch.ones(5,5):float(),'same');				
				gb_gcam_th = image.convolve(gb_gcam_th,image.gaussian(conv_size,conv_size):float(),'same');
				gb_gcam_th:div(torch.max(gb_gcam_th));
				gb_gcam_th[gb_gcam_th:gt(0.5)]=1;

				local im_blur=torch.cmul(gb_gcam_th,im_g)+torch.cmul((1-gb_gcam_th),im_org);
				local out_file_blur = out_file_pre..im_num..'_blur'..out_file_post;
				image.save(out_file_blur,image.toDisplayTensor(im_blur));
								
				image.save(out_file_gb_gcam_th, image.toDisplayTensor(gb_gcam_th))
		    	image.save(out_file_gb_gcam, image.toDisplayTensor(gb_gcam))
		    	image.save(out_file_gb_gcam_org, image.toDisplayTensor(gb_gcam_org))
		    	image.save(out_file_hm, image.toDisplayTensor(hm))
		    	image.save(out_file_org, image.toDisplayTensor(inputs_org[im_num][1]))

		    end
		end

	    local loss = torch.sum(batch_targets:eq(pred_labels))/batch_targets:nElement();

	    val_losses[#val_losses+1]=loss;
	    val_losses_iter[#val_losses_iter+1]=i;

	    net:training();
	    disp_str=string.format("minibatches processed: %6s, val loss = %6.6f", i, val_losses[#val_losses])
	    logger:writeString(dump.tostring(disp_str)..'\n');
	    npy4th.savenpy(out_file_pred_labels,pred_labels);
	    print(disp_str)
   		-- end
   	end
    local out_dir_diff=paths.concat(params.outDir,'diff_im_1');
    paths.mkdir(out_dir_diff);
	local data_params={file_path=params.val_data_path,
                batch_size=64,
                mean_file=params.mean_im_path,
                std_file=params.std_im_path,
                augmentation=false,
                limit=params.limit,
                out_dir_diff=out_dir_diff
                };
	local vd=data_face(data_params);
	vd:saveDifficultImages(net,net_gb,params.layer_to_viz,0.05,5);


    collectgarbage();
end

function testTwoListData(params)
    print ('setting_threads');
    torch.setnumthreads(1);
	local out_dir=params.outDir
    local net_file=params.model
    if params.limit<0 then
    	params.limit=nil;
    end
    
    paths.mkdir(out_dir);
    local out_dir_intermediate=paths.concat(out_dir,'images');
    paths.mkdir(out_dir_intermediate);
    local out_file_log=paths.concat(out_dir_intermediate,'log.txt');
    local out_file_pred_labels_post='_pred_labels.npy';

    local logger=torch.DiskFile(out_file_log,'w');

    logger:writeString(dump.tostring(params)..'\n');
    print (params);

    cutorch.setDevice(params.gpu);


    logger:writeString(dump.tostring('loading network')..'\n');
    print ('loading network');
    local net = torch.load(net_file);
    -- net:remove(#net);
    -- net:remove(12);
    logger:writeString(dump.tostring('done loading network')..'\n');
    print ('done loading network');
    print (net);

    logger:writeString(dump.tostring('making cuda')..'\n');
    print ('making cuda');
    net = net:cuda();
    logger:writeString(dump.tostring('done')..'\n');
    print ('done');

    logger:writeString(dump.tostring('loading params')..'\n');
    print ('loading params');
    local parameters, gradParameters = net:parameters()
    logger:writeString(dump.tostring('loading done')..'\n');
    print ('loading done');
    data_params={file_path=params.val_data_path,
                batch_size=params.batchSizeTest,
                mean_file=params.mean_im_path,
                std_file=params.std_im_path,
                augmentation=false,
                limit=params.limit};
	vd=data_face(data_params);

	local val_losses={};
	local val_losses_iter={};

	local net_gb= net:clone();
	net_gb:replace(utils.guidedbackprop);
	net_gb:evaluate();
	net_gb=net_gb:cuda();
	net:evaluate();
	
    local out_dir_diff=paths.concat(params.outDir,'diff_im_1');
    paths.mkdir(out_dir_diff);
	local data_params={file_path=params.val_data_path,
                batch_size=64,
                mean_file=params.mean_im_path,
                std_file=params.std_im_path,
                augmentation=false,
                limit=params.limit,
                out_dir_diff=out_dir_diff
                };
	local vd=data_face(data_params);
	-- print ('getTrainingData plain');
	-- vd:getTrainingData();
	print ('saving difficult');
	vd:saveDifficultImages(net,net_gb,params.layer_to_viz,0.05,5,logger);
	-- print ('getTrainingData plain');
	-- vd:getTrainingData();
	print ('getTrainingData 0.5');
	vd:getTrainingData(0.5);
	print ('getTrainingData 1');
	vd:getTrainingData(1);
	local batch_targets=vd.training_set.label:cuda();
   	local outputs = net:forward(vd.training_set.data:cuda());
   	local scores, pred_labels = torch.max(outputs, 2);
	pred_labels = pred_labels:type(batch_targets:type());
    pred_labels = pred_labels:view(batch_targets:size());
    local loss = torch.sum(batch_targets:eq(pred_labels))/batch_targets:nElement();
    print (loss);



	local out_file_pre = paths.concat(params.outDir,'viz_batch');
	paths.mkdir(out_file_pre);
	local batch_inputs=vd.training_set.data;
	print (batch_inputs:size())
    local inputs_org=unMean(batch_inputs,vd.mean_im,vd.std_im):div(255):float();
    for im_num=1,inputs_org:size(1) do
		local out_file_org=paths.concat(out_file_pre,im_num..'_org.jpg');
    	image.save(out_file_org, image.toDisplayTensor(inputs_org[im_num][1]))
   	end


	print ('getTrainingData 0');
	vd:getTrainingData(0);
	local batch_targets=vd.training_set.label:cuda();
   	local outputs = net:forward(vd.training_set.data:cuda());
   	local scores, pred_labels = torch.max(outputs, 2);
	pred_labels = pred_labels:type(batch_targets:type());
    pred_labels = pred_labels:view(batch_targets:size());
    local loss = torch.sum(batch_targets:eq(pred_labels))/batch_targets:nElement();
    print (loss);


	-- local out_file_pre = paths.concat(params.outDir,'viz_batch');
	-- paths.mkdir(out_file_pre);
	-- local batch_inputs=vd.training_set.data;

 --    local inputs_org=unMean(batch_inputs,vd.mean_im,vd.std_im):div(255):float();
 --    for im_num=1,inputs_org:size(1) do
	-- 	local out_file_org=paths.concat(out_file_pre,im_num..'_org.jpg');
 --    	image.save(out_file_org, image.toDisplayTensor(inputs_org[im_num][1]))
 --   	end

 --   	local batch_targets=vd.training_set.label:cuda();
 --   	local outputs = net:forward(vd.training_set.data:cuda());
 --   	local scores, pred_labels = torch.max(outputs, 2);
	-- pred_labels = pred_labels:type(batch_targets:type());
 --    pred_labels = pred_labels:view(batch_targets:size());
 --    local loss = torch.sum(batch_targets:eq(pred_labels))/batch_targets:nElement();
 --    print loss;

    

    collectgarbage();
end


cmd = torch.CmdLine()
cmd:text()
cmd:text('Train Face network')
cmd:text()
cmd:text('Options')

local epoch_size=18;
-- 56;

cmd:option('-model','../experiments/khorrami_basic_aug_fix_resume_again/0/final/model_all_final.dat');
cmd:option('-outDir','../scratch/test_grad_cam/10');
-- cmd:option('-model','/home/SSD3/maheen-data/expression_project/scratch/train_aug_fix/0/intermediate/model_all_500.dat');
-- cmd:option('-outDir','../scratch/test_grad_cam/11');
cmd:option('-mean_im_path','../data/ck_96/train_test_files/train_0_mean.png');
cmd:option('-std_im_path','../data/ck_96/train_test_files/train_0_std.png');

cmd:option('-limit',-1,'num of training data to read');

cmd:option('-val_data_path','../data/ck_96/train_test_files/test_0.txt')
cmd:option('-iterationsTest',1,'num of iterations to run');
cmd:option('-batchSizeTest',132,'batch size');


cmd:option('-gpu',1,'gpu to run the training on');
cmd:option('-layer_to_viz',8,'gpu to run the training on');



params = cmd:parse(arg)
-- main(params);    
testTwoListData(params)
