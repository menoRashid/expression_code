require 'image'
npy4th = require 'npy4th'
require 'data_face';
require 'cunn'
require 'cudnn'
require 'nn';
require 'optim'
require 'torchx';
require 'gnuplot';
dump=require 'dump';
visualize=require 'visualize';
utils = require 'misc.utils'


function unMean(training_data,mean,std)
	local mean=mean:view(1,mean:size(1),mean:size(2),mean:size(3));
	local std=std:view(1,std:size(1),std:size(2),std:size(3));
	mean=torch.repeatTensor(mean,training_data:size(1),1,1,1):type(training_data:type());
	std=torch.repeatTensor(std,training_data:size(1),1,1,1):type(training_data:type());
	training_data=torch.cmul(training_data,std)+mean;
	return training_data;
end	

function meanIt(training_data,mean,std)
	local mean=mean:view(1,mean:size(1),mean:size(2),mean:size(3));
	local std=std:view(1,std:size(1),std:size(2),std:size(3));
	mean=torch.repeatTensor(mean,training_data:size(1),1,1,1):type(training_data:type());
	std=torch.repeatTensor(std,training_data:size(1),1,1,1):type(training_data:type());
	training_data=torch.cdiv(training_data-mean,std);
	return training_data;
end	

function main(params) 
    print ('setting_threads');
    torch.setnumthreads(1);
	local out_dir=params.outDir
    local net_file=params.model
    if params.limit<0 then
    	params.limit=nil;
    end
    
    paths.mkdir(out_dir);
    local out_dir_intermediate=paths.concat(out_dir,'images');
    paths.mkdir(out_dir_intermediate);
    local out_file_log=paths.concat(out_dir_intermediate,'log.txt');
    local out_file_pred_labels_post='_pred_labels.npy';

    local logger=torch.DiskFile(out_file_log,'w');

    logger:writeString(dump.tostring(params)..'\n');
    print (params);

    cutorch.setDevice(params.gpu);


    logger:writeString(dump.tostring('loading network')..'\n');
    print ('loading network');
    local net = torch.load(net_file);
    -- net:remove(#net);
    -- net:remove(12);
    logger:writeString(dump.tostring('done loading network')..'\n');
    print ('done loading network');
    print (net);

    logger:writeString(dump.tostring('making cuda')..'\n');
    print ('making cuda');
    net = net:cuda();
    logger:writeString(dump.tostring('done')..'\n');
    print ('done');

    logger:writeString(dump.tostring('loading params')..'\n');
    print ('loading params');
    local parameters, gradParameters = net:parameters()
    logger:writeString(dump.tostring('loading done')..'\n');
    print ('loading done');
    data_params={file_path=params.val_data_path,
                batch_size=params.batchSizeTest,
                mean_file=params.mean_im_path,
                std_file=params.std_im_path,
                augmentation=false,
                limit=params.limit};
	vd=data_face(data_params);

	local val_losses={};
	local val_losses_iter={};

	local net_gb= net:clone();
	net_gb:replace(utils.guidedbackprop);
	net_gb:evaluate();
	net_gb=net_gb:cuda();
	net:training();
	print ('training',net.train);
	net:evaluate();
	print ('evaluating',net.train);
    
    -- local i=1;

	local emotions={'neutral', 'anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise'} 
	local layer_to_viz=params.layer_to_viz;

    for i=1,params.iterationsTest do
    	net:zeroGradParameters();
    	net_gb:zeroGradParameters();
	    local out_file_pred_labels=paths.concat(out_dir,i..out_file_pred_labels_post);
		vd:getTrainingData();

	    vd.training_set.data=vd.training_set.data:cuda();
		vd.training_set.label=vd.training_set.label:cuda();
		local batch_inputs=vd.training_set.data;
		local batch_targets=vd.training_set.label;
		local outputs=net:forward(batch_inputs);
		local outputs_gb= net_gb:forward(batch_inputs);

		local scores, pred_labels = torch.max(outputs, 2);
		pred_labels = pred_labels:type(batch_targets:type());
	    pred_labels = pred_labels:view(batch_targets:size());

	    local doutput_pred = utils.create_grad_input_batch(net.modules[#net.modules], pred_labels)
	    local gcam_pred = utils.grad_cam_batch(net, layer_to_viz, doutput_pred);
	    net:zeroGradParameters();
	    local doutput_gt =	utils.create_grad_input_batch(net.modules[#net.modules], batch_targets)
	    local gcam_gt = utils.grad_cam_batch(net, layer_to_viz, doutput_gt);
	    local gb_viz_pred = net_gb:backward(batch_inputs, doutput_pred)
	    net_gb:zeroGradParameters();
	    local gb_viz_gt = net_gb:backward(batch_inputs, doutput_gt)
	    
	    local inputs_org=unMean(batch_inputs,vd.mean_im,vd.std_im):div(255);
	    
	    local conv_size=11;
	    local gauss_big = image.gaussian({height=conv_size,width=conv_size,normalize=true}):cuda();
	    local gauss_layer = nn.SpatialConvolution(1,1,conv_size,conv_size,
	    										1,1,(conv_size-1)/2,(conv_size-1)/2):cuda();
	    gauss_layer.weight=gauss_big:view(1,1,gauss_big:size(1),gauss_big:size(2)):clone()
	    gauss_layer.bias:fill(0);
	    
	    conv_size=5;
	    local gauss =  image.gaussian({height=conv_size,width=conv_size,normalize=true}):cuda();
		local gauss_layer_small = nn.SpatialConvolution(1,1,conv_size,conv_size,
	    										1,1,(conv_size-1)/2,(conv_size-1)/2):cuda();
	    gauss_layer_small.weight = gauss:view(1,1,gauss:size(1),gauss:size(2)):clone()
	    gauss_layer_small.bias:fill(0);
	    
	    local up_layer = nn.SpatialUpSamplingBilinear({oheight=inputs_org:size(3),owidth=inputs_org:size(4)}):cuda();

        local min_layer = nn.Sequential();
        min_layer:add(nn.View(-1):setNumInputDims(3));
        min_layer:add(nn.Min(1,1));
        min_layer:add(nn.View(1));
        min_layer:add(nn.Replicate(inputs_org:size(3),2,3));
        min_layer:add(nn.Replicate(inputs_org:size(4),3,3));
        min_layer = min_layer:cuda();

        local max_layer = min_layer:clone();
        max_layer:remove(2);
        max_layer:insert(nn.Max(1,1),2);
        max_layer:cuda();
        
	    local inputs_blur=gauss_layer:forward(inputs_org);
	    inputs_blur:cdiv(max_layer:forward(inputs_blur:csub(min_layer:forward(inputs_blur))));
        local im_blur_all;
	    for gt_pred=1,2 do
	    	local gcam_curr;
	    	local gb_viz_curr;
	    	local out_file_pre=paths.concat(out_dir_intermediate,i..'_');
	    	local out_file_post;
	    	if gt_pred==1 then
	    		gcam_curr=gcam_pred;
	    		gb_viz_curr=gb_viz_pred;
	    		out_file_post='_pred.jpg';
	    	else
	    		gcam_curr=gcam_gt;
	    		gb_viz_curr=gb_viz_gt;
	    		out_file_post='_gt.jpg';
	    	end
	    	
	    	gcam_curr = up_layer:forward(gcam_curr);
	    	local gb_gcam_org_all = torch.cmul(gb_viz_curr,gcam_curr);
	    	local gb_gcam_all = torch.abs(gb_gcam_org_all);
	    	gb_gcam_all:cdiv(max_layer:forward(gb_gcam_all:csub(min_layer:forward(gb_gcam_all))));
	    	
	    	local gb_gcam_th_all =torch.zeros(gb_gcam_all:size()):type(gb_gcam_all:type());
	    	local vals_all = gb_gcam_th_all:clone();
	    	for im_num =1, inputs_org:size(1) do
	    		local gb_gcam = gb_gcam_all[im_num][1];
	    		local gb_gcam_vals = torch.sort(gb_gcam:view(-1),1,true);
				local val = gb_gcam_vals[math.floor(gb_gcam_vals:size(1)*0.05)];
				vals_all[im_num][1]:fill(val);
	    	end
	    	gb_gcam_th_all[gb_gcam_all:ge(vals_all)]=1;
	    	gb_gcam_th_all[gb_gcam_all:lt(vals_all)]=0;
	    	gb_gcam_th_all=gauss_layer_small:forward(gb_gcam_th_all);
	    	gb_gcam_th_all:cdiv(max_layer:forward(gb_gcam_th_all:csub(min_layer:forward(gb_gcam_th_all))));
			
			im_blur_all=torch.cmul(gb_gcam_th_all,inputs_blur)+torch.cmul((1-gb_gcam_th_all),inputs_org);
				-- 3,7.6,12,18.2,25

		    for im_num=1,inputs_org:size(1) do
		    	if not torch.all(torch.eq(gcam_pred[im_num],gcam_gt[im_num])) then
		    		print (im_num);
		    	end
		    	local out_file_org=out_file_pre..im_num..'_org.jpg';
				local out_file_hm=out_file_pre..im_num..'_hm'..out_file_post;
				local out_file_gb_gcam=out_file_pre..im_num..'_gb_gcam'..out_file_post;
				local out_file_gb_gcam_org=out_file_pre..im_num..'_gb_gcam_org'..out_file_post;
				local out_file_gb_gcam_th=out_file_pre..im_num..'_gb_gcam_th'..out_file_post;
				local out_file_g = out_file_pre..im_num..'_gaussian'..out_file_post;
				local out_file_blur = out_file_pre..im_num..'_blur'..out_file_post;
				
				local gcam=gcam_curr[im_num]
		    	local gb_gcam = gb_gcam_all[im_num];
		    	local gb_gcam_org = gb_gcam_org_all[im_num]
		    	local hm = utils.to_heatmap(gcam:float())
		    	local im_org = inputs_org[im_num][1];
				local im_g = inputs_blur[im_num][1];
				local gb_gcam_th = gb_gcam_th_all[im_num][1];
				local im_blur = im_blur_all[im_num][1]

				-- print ('gcam',torch.min(gcam),torch.max(gcam));
		  --   	print ('gb_gcam',torch.min(gb_gcam),torch.max(gb_gcam));
		  --   	print ('gb_gcam_org',torch.min(gb_gcam_org),torch.max(gb_gcam_org));
		  --   	print ('hm',torch.min(hm),torch.max(hm));
		  --   	print ('im_org',torch.min(im_org),torch.max(im_org));
				-- print ('im_g',torch.min(im_g),torch.max(im_g));
				-- print ('gb_gcam_th',torch.min(gb_gcam_th),torch.max(gb_gcam_th));
				-- print ('im_blur',torch.min(im_blur),torch.max(im_blur));

				image.save(out_file_blur,image.toDisplayTensor(im_blur));
				image.save(out_file_gb_gcam_th, image.toDisplayTensor(gb_gcam_th))
		    	image.save(out_file_gb_gcam, image.toDisplayTensor(gb_gcam))
		    	image.save(out_file_gb_gcam_org, image.toDisplayTensor(gb_gcam_org))
		    	image.save(out_file_hm, image.toDisplayTensor(hm))
		    	image.save(out_file_org, image.toDisplayTensor(im_org))
		    	image.save(out_file_g,image.toDisplayTensor(im_g));
	   		end
			
		end

	    local loss = torch.sum(batch_targets:eq(pred_labels))/batch_targets:nElement();
	    print (loss);
	    local outputs=net:forward(meanIt(im_blur_all:mul(255),vd.mean_im,vd.std_im));
		-- local outputs_gb= net_gb:forward(batch_inputs);

		local scores, pred_labels = torch.max(outputs, 2);
		pred_labels = pred_labels:type(batch_targets:type());
	    pred_labels = pred_labels:view(batch_targets:size());
	    local loss = torch.sum(batch_targets:eq(pred_labels))/batch_targets:nElement();
	    print (loss);

	    val_losses[#val_losses+1]=loss;
	    val_losses_iter[#val_losses_iter+1]=i;

	    net:training();
	    disp_str=string.format("minibatches processed: %6s, val loss = %6.6f", i, val_losses[#val_losses])
	    logger:writeString(dump.tostring(disp_str)..'\n');
	    npy4th.savenpy(out_file_pred_labels,pred_labels);
	    print(disp_str)
   		-- end
   	end
 --    local out_dir_diff=paths.concat(params.outDir,'diff_im_1');
 --    paths.mkdir(out_dir_diff);
	-- local data_params={file_path=params.val_data_path,
 --                batch_size=64,
 --                mean_file=params.mean_im_path,
 --                std_file=params.std_im_path,
 --                augmentation=false,
 --                limit=params.limit,
 --                out_dir_diff=out_dir_diff
 --                };
	-- local vd=data_face(data_params);
	-- vd:saveDifficultImages(net,net_gb,params.layer_to_viz,0.05,5);


    collectgarbage();
end

function testTwoListData(params)
    print ('setting_threads');
    torch.setnumthreads(1);
	local out_dir=params.outDir
    local net_file=params.model
    if params.limit<0 then
    	params.limit=nil;
    end
    
    paths.mkdir(out_dir);
    local out_dir_intermediate=paths.concat(out_dir,'images');
    paths.mkdir(out_dir_intermediate);
    local out_file_log=paths.concat(out_dir_intermediate,'log.txt');
    local out_file_pred_labels_post='_pred_labels.npy';

    local logger=torch.DiskFile(out_file_log,'w');

    logger:writeString(dump.tostring(params)..'\n');
    print (params);

    cutorch.setDevice(params.gpu);


    logger:writeString(dump.tostring('loading network')..'\n');
    print ('loading network');
    local net = torch.load(net_file);
    logger:writeString(dump.tostring('done loading network')..'\n');
    print ('done loading network');
    print (net);

    logger:writeString(dump.tostring('making cuda')..'\n');
    print ('making cuda');
    net = net:cuda();
    logger:writeString(dump.tostring('done')..'\n');
    print ('done');

    logger:writeString(dump.tostring('loading params')..'\n');
    print ('loading params');
    local parameters, gradParameters = net:parameters()
    logger:writeString(dump.tostring('loading done')..'\n');
    print ('loading done');
    
	local val_losses={};
	local val_losses_iter={};

	local net_gb= net:clone();
	net_gb:replace(utils.guidedbackprop);
	-- net_gb:evaluate();
	net_gb=net_gb:cuda();

	print ('nets train mode',net_gb.train,net.train);
	-- net:evaluate();
	
    local out_dir_diff=paths.concat(params.outDir,'test_buildBlurryBatch'); 
    paths.mkdir(out_dir_diff);
    local out_file_pre = paths.concat(out_dir_diff,'1_');

	local data_params={file_path=params.val_data_path,
                batch_size=params.batchSizeTest,
                mean_file=params.mean_im_path,
                std_file=params.std_im_path,
                augmentation=true,
                limit=params.limit,
                out_dir_diff=out_dir_diff
                };
	local vd=data_face(data_params);
	
	vd:buildBlurryBatch(net,net_gb,params.layer_to_viz,0.05,5,nil,out_file_pre);
	local batch_targets=vd.training_set.label;

	print ('nets train mode',net_gb.train,net.train);
	net:evaluate();

	local outputs=net:forward(vd.training_set.data:cuda());


	local scores, pred_labels = torch.max(outputs, 2);
	pred_labels = pred_labels:type(batch_targets:type());
    pred_labels = pred_labels:view(batch_targets:size());
    local loss = torch.sum(batch_targets:eq(pred_labels))/batch_targets:nElement();
    print (loss);


	vd:getTrainingData();
	batch_targets=vd.training_set.label;
	outputs=net:forward(vd.training_set.data:cuda());
	scores, pred_labels = torch.max(outputs, 2);
	pred_labels = pred_labels:type(batch_targets:type());
    pred_labels = pred_labels:view(batch_targets:size());
    loss = torch.sum(batch_targets:eq(pred_labels))/batch_targets:nElement();
    print (loss);
	    

	

    collectgarbage();
end


cmd = torch.CmdLine()
cmd:text()
cmd:text('Train Face network')
cmd:text()
cmd:text('Options')

local epoch_size=18;
-- 56;

cmd:option('-model','../experiments/khorrami_basic_aug_fix_resume_again/0/final/model_all_final.dat');
cmd:option('-outDir','../scratch/test_grad_cam/10');
-- cmd:option('-model','/home/SSD3/maheen-data/expression_project/scratch/train_aug_fix/0/intermediate/model_all_500.dat');
-- cmd:option('-outDir','../scratch/test_grad_cam/11');
cmd:option('-mean_im_path','../data/ck_96/train_test_files/train_0_mean.png');
cmd:option('-std_im_path','../data/ck_96/train_test_files/train_0_std.png');

cmd:option('-limit',-1,'num of training data to read');

cmd:option('-val_data_path','../data/ck_96/train_test_files/test_0.txt')
cmd:option('-iterationsTest',1,'num of iterations to run');
cmd:option('-batchSizeTest',132,'batch size');


cmd:option('-gpu',1,'gpu to run the training on');
cmd:option('-layer_to_viz',8,'gpu to run the training on');



params = cmd:parse(arg)
-- main(params);    
testTwoListData(params)
