require 'image'
npy4th = require 'npy4th'
require 'data_face_meanFirst_withAnno';
require 'cunn'
require 'cudnn'
require 'nn';
require 'optim'
require 'torchx';
require 'gnuplot';
dump=require 'dump';
visualize=require 'visualize';
utils = require 'misc.utils'


function main(params) 
    print ('setting_threads');
    torch.setnumthreads(1);
	local data_path=params.data_path;
	local out_dir=params.outDir
    local net_file=params.model
    if params.limit<0 then
    	params.limit=nil;
    end
    local val_data_path;
    local val_human_path
    if params.testAfter>0 then
    	val_data_path= params.val_data_path
    end

    paths.mkdir(out_dir);
    local out_dir_images=paths.concat(out_dir,'test_images');
    paths.mkdir(out_dir_images);
    
    local net=torch.load(params.model);

    
    local data_params={file_path=params.val_data_path,
					batch_size=params.batchSize,
					mean_file=params.mean_im_path,
					std_file=params.std_im_path,
					augmentation=params.augmentation,
					limit=params.limit,
                    ratio_blur=params.ratioBlur,
                    activation_upper=activation_upper,
                    conv_size=params.conv_size,
                    net=net:clone(),
                    -- net_gb=nil,
                    optimize=params.optimize,
                    twoClass=params.twoClass,
                    numAnnos=params.numAnnos
                    };

	local td=data_face(data_params);
    local pointSize=15;

    net=net:cuda();
    net:evaluate();
    -- local bin_blur=torch.Tensor({1,1,1,1,1})
    -- local bin_blur=torch.Tensor({0,0,0,0,0})
    local batch_num=1;
    
    for pointToBlur=1,5,1 do
        local bin_blur=torch.zeros(5);
        bin_blur[pointToBlur]=1;
        td:buildBlurryBatch(pointSize,bin_blur);
        local preds=net:forward(td.training_set.data:clone());
        local indices=torch.zeros(preds:size()):type(preds:type());
        indices[preds:gt(0)]=1;
        indices[preds:le(0)]=-1;
        indices=indices:view(td.training_set.label:size())
        local bin_keep=td.training_set.label:eq(indices)
        
        print (pointToBlur,torch.sum(bin_keep)/td.training_set.label:nElement());

        local im_all;
        if params.augmentation then
            im_all=td.training_set.data;
        else
            im_all=td:unMean(td.mean_batch:cuda(),td.std_batch:cuda());
        end
        -- local im_all=td.training_set.data;
        local labels=td.training_set.labels;
        local annos_all=td.training_set.anno;
        for im_num=1,im_all:size(1) do
            local im_curr=im_all[im_num];
            local annos_curr=annos_all[im_num];
            local out_file_curr=paths.concat(out_dir_images,batch_num..'_'..im_num..'.jpg');

            image.save(out_file_curr,image.toDisplayTensor(im_curr));
        end

    end

    local py_str='python ../python/visualizeForFolder.py '..out_dir_images..' '..'.jpg';
    os.execute(py_str)
end



cmd = torch.CmdLine()
cmd:text()
cmd:text('Train Face network')
cmd:text()
cmd:text('Options')

local epoch_size=10;
-- local scheme = 'ncl';
local temp ='../scratch/test_anno_points'
-- '../experiments/khorrami_withBlur_test/fix_'..scheme;


-- cmd:option('-model','../models/base_khorrami_model_1.dat');
cmd:option('-model','../experiments/happy_neutral/bl/happy_neutral_withAnno/final/model_all_final.dat');
cmd:option('-mean_im_path','../data/ck_96/train_test_files/train_happy_neutral_mean.png');
cmd:option('-std_im_path','../data/ck_96/train_test_files/train_happy_neutral_std.png');

cmd:option('-limit',-1,'num of training data to read');
cmd:option('-iterations',1,'num of iterations to run');

cmd:option('-ratioBlur',1);
cmd:option('-startingActivation',0);
cmd:option('-fixThresh',-1);
cmd:option('-incrementDifficultyAfter',0);
cmd:option('-activationThreshMax',0.5);
cmd:option('-scheme','ncl');
cmd:option('-conv_size',5);
cmd:option('-layer_to_viz',8);
cmd:option('-optimize',true);
cmd:option('-numAnnos',5);
cmd:option('-overwrite',true);

cmd:option('-saveAfter',10*epoch_size,'num of iterations after which to save model');
cmd:option('-batchSize',54,'batch size');
cmd:option('-testAfter',10*epoch_size,'num iterations after which to get validation loss');
cmd:option('-dispAfter',1,'num iterations after which to display training loss');
cmd:option('-dispPlotAfter',10*epoch_size,'num iterations after which to plot loss curves');

cmd:option('-val_data_path','../data/ck_96/train_test_files/test_happy_neutral_withAnno.txt')
cmd:option('-data_path','../data/ck_96/train_test_files/train_happy_neutral_withAnno.txt')
-- cmd:option('-weights_file','../data/ck_96/train_test_files/train_0_weights.npy')
cmd:option('-iterationsTest',1,'num of iterations to run');
cmd:option('-batchSizeTest',132,'batch size');

cmd:option('learningRate', 1e-2)
cmd:option('weightDecay', 1e-5)
cmd:option('momentum', 0.9)

cmd:option('augmentation' , false);

cmd:option('-gpu',1,'gpu to run the training on');
cmd:option('-outDir',temp);
cmd:option('-modelTest',paths.concat(temp,'final/model_all_final.dat'));

cmd:option('-twoClass',true);

params = cmd:parse(arg)
main(params);    

-- cmd:option('-iterations',1,'num of iterations to run');
-- cmd:option('-batchSize',132,'batch size');

-- cmd:option('-outDirTest',paths.concat(params.outDir,'test_images'));
-- params = cmd:parse(arg)
-- test(params);
-- testGlobal();
